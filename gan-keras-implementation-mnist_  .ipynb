{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# GAN for Generating MNIST Handwritten Digits","metadata":{}},{"cell_type":"markdown","source":"#### Importing Libraries","metadata":{"tags":[]}},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Concatenate\nfrom tensorflow.keras.layers import BatchNormalization, Activation, Embedding, multiply\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Conv2D, Conv2DTranspose\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.utils import to_categorical\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n%matplotlib inline","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","tags":[],"execution":{"iopub.status.busy":"2022-08-15T00:59:10.003788Z","iopub.execute_input":"2022-08-15T00:59:10.004129Z","iopub.status.idle":"2022-08-15T00:59:10.884496Z","shell.execute_reply.started":"2022-08-15T00:59:10.004038Z","shell.execute_reply":"2022-08-15T00:59:10.883757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Loading data","metadata":{}},{"cell_type":"code","source":"# load the mnist dataset \n(x_train, y_train), (x_test, y_test)  = tf.keras.datasets.mnist.load_data()\nprint('Train', x_train.shape, y_train.shape)\nprint('Test', x_test.shape, y_test.shape)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-08-15T00:59:10.885651Z","iopub.execute_input":"2022-08-15T00:59:10.885912Z","iopub.status.idle":"2022-08-15T00:59:11.280685Z","shell.execute_reply.started":"2022-08-15T00:59:10.885869Z","shell.execute_reply":"2022-08-15T00:59:11.279807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plot raw pixel data\nplt.imshow(x_train[10], cmap='gray')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-08-15T00:59:11.283069Z","iopub.execute_input":"2022-08-15T00:59:11.283534Z","iopub.status.idle":"2022-08-15T00:59:11.570407Z","shell.execute_reply.started":"2022-08-15T00:59:11.283479Z","shell.execute_reply":"2022-08-15T00:59:11.569354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_shape = (28, 28, 1)\nnoise_dim = 100\nnum_classes = 10","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","tags":[],"execution":{"iopub.status.busy":"2022-08-15T00:59:11.571911Z","iopub.execute_input":"2022-08-15T00:59:11.572186Z","iopub.status.idle":"2022-08-15T00:59:11.577014Z","shell.execute_reply.started":"2022-08-15T00:59:11.572138Z","shell.execute_reply":"2022-08-15T00:59:11.576040Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocessing Dataset","metadata":{}},{"cell_type":"code","source":"# normalizing\n# scale from [0,255] to [-1,1]\nX_train = (x_train - 127.5) / 127.5\nX_train = np.expand_dims(X_train, axis=3)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-08-15T00:59:11.578290Z","iopub.execute_input":"2022-08-15T00:59:11.578808Z","iopub.status.idle":"2022-08-15T00:59:11.910171Z","shell.execute_reply.started":"2022-08-15T00:59:11.578757Z","shell.execute_reply":"2022-08-15T00:59:11.909437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling","metadata":{}},{"cell_type":"markdown","source":"### Generator model","metadata":{}},{"cell_type":"code","source":"def def_generator(noise_dim):\n    \n    model = Sequential()\n    \n    model.add(Dense(7*7*256, input_shape=(noise_dim, )))\n    model.add(Reshape((7, 7, 256)))\n    \n    # 7*7*256 => 14*14*128\n    model.add(Conv2DTranspose(128, kernel_size=3, strides=2, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    \n    # 14*14*128 => 14*14*64\n    model.add(Conv2DTranspose(64, kernel_size=3, strides=1, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    \n    # 14*14*64 => 28*28*1\n    model.add(Conv2DTranspose(1, kernel_size=3, strides=2, padding='same'))\n    model.add(Activation('tanh'))\n    \n    z = Input(shape=(noise_dim, ))\n    \n    # Conditioning label\n    label = Input(shape=(1,), dtype='int32')\n    \n    # embedding layer:\n    # turns labels into dense vectors of size noise_dim\n    # produces 3D tensor with shape: (batch_size, 1, noise_dim)\n    label_embedding = Embedding(num_classes, noise_dim, input_length=1)(label)\n    \n    # Flatten the embedding 3D tensor into 2D  tensor with shape: (batch_size, noise_dim)\n    label_embedding = Flatten()(label_embedding)\n    \n    # Element-wise product of the vectors z and the label embeddings\n    joined_representation = multiply([z, label_embedding])\n    \n    img = model(joined_representation)\n    \n    return Model([z, label], img)\n","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-08-15T00:59:11.911607Z","iopub.execute_input":"2022-08-15T00:59:11.911876Z","iopub.status.idle":"2022-08-15T00:59:11.921146Z","shell.execute_reply.started":"2022-08-15T00:59:11.911826Z","shell.execute_reply":"2022-08-15T00:59:11.920366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# creating the generator model\ngen = def_generator(noise_dim)\ngen.summary()\n# the generator takes noise and the target label as input\n# and generates the corresponding digit for that label","metadata":{"execution":{"iopub.status.busy":"2022-08-15T00:59:11.922516Z","iopub.execute_input":"2022-08-15T00:59:11.923107Z","iopub.status.idle":"2022-08-15T00:59:12.319903Z","shell.execute_reply.started":"2022-08-15T00:59:11.922747Z","shell.execute_reply":"2022-08-15T00:59:12.319231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## The Discriminator","metadata":{}},{"cell_type":"code","source":"# define the standalone discriminator model\ndef def_discriminator(img_shape):\n    \n    model = Sequential()\n    \n    # 28*28*2 => 14*14*64\n    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=(28, 28, 2)))\n    model.add(LeakyReLU(alpha=0.01))\n    \n    # 14*14*64 => 7*7*64\n    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    \n    # 7*7*128 => 3*3*128\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same'))\n    model.add(BatchNormalization())\n    model.add(LeakyReLU(alpha=0.01))\n    \n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n    \n    img = Input(shape=img_shape)\n    \n    label = Input(shape=(1,), dtype='int32')\n    \n    # embedding layer:\n    # turns labels into dense vectors of size 28*28*1\n    # produces 3D tensor with shape: (batch_size, 1, 28*28*1)\n    label_embedding = Embedding(input_dim=num_classes, output_dim=np.prod(img_shape), input_length=1)(label)\n    # Flatten the embedding 3D tensor into 2D  tensor with shape: (batch_size, 28*28*1)\n    label_embedding = Flatten()(label_embedding)\n    # Reshape label embeddings to have same dimensions as input images\n    label_embedding = Reshape(img_shape)(label_embedding)\n    \n    # concatenate images with corresponding label embeddings\n    concatenated = Concatenate(axis=-1)([img, label_embedding])\n    \n    prediction = model(concatenated)\n    \n    return Model([img, label], prediction)\n","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-08-15T00:59:12.321772Z","iopub.execute_input":"2022-08-15T00:59:12.322036Z","iopub.status.idle":"2022-08-15T00:59:12.331331Z","shell.execute_reply.started":"2022-08-15T00:59:12.321987Z","shell.execute_reply":"2022-08-15T00:59:12.328848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# building and compiling the Discriminator\ndisc = def_discriminator(img_shape)\ndisc.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam())\ndisc.summary()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T00:59:12.332669Z","iopub.execute_input":"2022-08-15T00:59:12.332973Z","iopub.status.idle":"2022-08-15T00:59:12.804424Z","shell.execute_reply.started":"2022-08-15T00:59:12.332904Z","shell.execute_reply":"2022-08-15T00:59:12.802811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## GAN model","metadata":{}},{"cell_type":"code","source":"\nz = Input(shape=(noise_dim,))\nlabel = Input(shape=(1,))\n\nimg = gen([z, label])\n\n# keep the discriminator's params constant for generator training\ndisc.trainable = False\n\nprediction = disc([img, label])\n\n# Conditional (Conditional) GAN model with fixed discriminator to train the generator\ncgan = Model([z, label], prediction)\ncgan.compile(loss='binary_crossentropy', optimizer=Adam())\ncgan.summary()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-08-15T00:59:12.808013Z","iopub.execute_input":"2022-08-15T00:59:12.808292Z","iopub.status.idle":"2022-08-15T00:59:13.132515Z","shell.execute_reply.started":"2022-08-15T00:59:12.808239Z","shell.execute_reply":"2022-08-15T00:59:13.131847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to display images\ndef display_images(epoch,image_grid_rows=2, image_grid_columns=5):\n    z = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, noise_dim))\n    labels = np.arange(0, 10).reshape(-1, 1)\n    gen_imgs = gen.predict([z, labels])\n    gen_imgs = 0.5 * gen_imgs + 0.5\n    fig, axs = plt.subplots(image_grid_rows, image_grid_columns, figsize=(10,4), sharey=True, sharex=True)\n    fig.suptitle('ittr:'+str(epoch), fontsize=10)\n    cnt = 0\n    for i in range(image_grid_rows):\n        for j in range(image_grid_columns):\n            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n            axs[i,j].axis('off')\n            axs[i,j].set_title(\"Digit: %d\" % labels[cnt])\n            cnt += 1\n    plt.savefig('itter'+str(epoch)+'.png')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-08-15T00:59:13.135574Z","iopub.execute_input":"2022-08-15T00:59:13.135806Z","iopub.status.idle":"2022-08-15T00:59:13.143212Z","shell.execute_reply.started":"2022-08-15T00:59:13.135757Z","shell.execute_reply":"2022-08-15T00:59:13.142220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training","metadata":{}},{"cell_type":"code","source":"accuracies = []\nlosses = []\n\ndef train(iterations, batch_size, sample_interval = 500):\n\n    \n    real = np.ones(shape=(batch_size, 1))\n    fake = np.zeros(shape=(batch_size, 1))\n    \n    for iteration in range(iterations):\n        \n        idx = np.random.randint(0, X_train.shape[0], batch_size)\n        imgs, labels = X_train[idx], y_train[idx]\n        \n        z = np.random.normal(0, 1, size=(batch_size, noise_dim))\n        gen_imgs = gen.predict([z, labels])\n        \n        d_loss_real = disc.train_on_batch([imgs, labels], real)\n        d_loss_fake = disc.train_on_batch([gen_imgs, labels], fake)\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n        \n        z = np.random.normal(0, 1, size=(batch_size, noise_dim))\n        labels = np.random.randint(0, num_classes, batch_size).reshape(-1, 1)\n        \n        g_loss = cgan.train_on_batch([z, labels], real)\n        \n        if iteration % sample_interval == 0:\n            print('{} >> G loss: {} D loss: {}, accuracy: {:.2f}'.format(iteration,g_loss, d_loss[0], 100 * d_loss[1] ))\n        \n            losses.append((d_loss[0], g_loss))\n            accuracies.append(d_loss[1])\n            \n            display_images(iteration)\n    ","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-08-15T00:59:13.144475Z","iopub.execute_input":"2022-08-15T00:59:13.144850Z","iopub.status.idle":"2022-08-15T00:59:13.154772Z","shell.execute_reply.started":"2022-08-15T00:59:13.144767Z","shell.execute_reply":"2022-08-15T00:59:13.154010Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20000\nbatch_size = 128\n\ntrain(epochs, batch_size)\n","metadata":{"_kg_hide-output":true,"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-08-15T00:59:13.156390Z","iopub.execute_input":"2022-08-15T00:59:13.156653Z","iopub.status.idle":"2022-08-15T01:12:25.309918Z","shell.execute_reply.started":"2022-08-15T00:59:13.156603Z","shell.execute_reply":"2022-08-15T01:12:25.309181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_loss,g_loss = np.hsplit(losses[0:15,:],2)\nd_loss.shape","metadata":{"execution":{"iopub.status.busy":"2022-08-15T01:30:11.397884Z","iopub.execute_input":"2022-08-15T01:30:11.398400Z","iopub.status.idle":"2022-08-15T01:30:11.404469Z","shell.execute_reply.started":"2022-08-15T01:30:11.398309Z","shell.execute_reply":"2022-08-15T01:30:11.403373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"losses = np.array(losses)\n# d_loss = losses[0]\n\n# Plot training losses for Discriminator and Generator\nplt.figure(figsize=(15, 5))\nplt.plot(range(0,15*500,500),d_loss.reshape(-1), label=\"Discriminator loss\")\nplt.plot(range(0,15*500,500),g_loss.reshape(-1), label=\"Generator loss\")\n\nplt.xticks(range(0,15*500,500), rotation=90)\n\nplt.title(\"Training Loss\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Loss\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2022-08-15T01:30:33.025631Z","iopub.execute_input":"2022-08-15T01:30:33.025939Z","iopub.status.idle":"2022-08-15T01:30:33.481960Z","shell.execute_reply.started":"2022-08-15T01:30:33.025875Z","shell.execute_reply":"2022-08-15T01:30:33.481192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Generating mnist Images","metadata":{"tags":[]}},{"cell_type":"code","source":"image_grid_rows=2\nimage_grid_columns=5\nz = np.random.normal(0, 1, (image_grid_rows * image_grid_columns, noise_dim))\nlabels = np.arange(0, 10).reshape(-1, 1)\ngen_imgs = gen.predict([z, labels])\ngen_imgs = 0.5 * gen_imgs + 0.5\nfig, axs = plt.subplots(image_grid_rows, image_grid_columns, figsize=(10,4), sharey=True, sharex=True)\ncnt = 0\nfor i in range(image_grid_rows):\n    for j in range(image_grid_columns):\n        axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n        axs[i,j].axis('off')\n        axs[i,j].set_title(\"Digit: %d\" % labels[cnt])\n        cnt += 1","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-08-15T01:12:25.863119Z","iopub.status.idle":"2022-08-15T01:12:25.863973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"digit = 9\n\nz = np.random.normal(0, 1, (1, noise_dim))\ngen_imgs = gen.predict([z, np.array(digit).reshape(-1,1)])\ngen_imgs = 0.5 * gen_imgs + 0.5\nplt.imshow(gen_imgs[0,:,:,0],cmap='gray')","metadata":{"tags":[],"execution":{"iopub.status.busy":"2022-08-15T01:12:25.864812Z","iopub.status.idle":"2022-08-15T01:12:25.865508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}